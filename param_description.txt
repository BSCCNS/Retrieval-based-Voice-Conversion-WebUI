

root = '/media/HDD_disk/tomas/ICHOIR/fork/Retrieval-based-Voice-Conversion-WebUI'
trainset_dir = f'{root}/data/1_16k_wavs'
exp_dir = 'maria-100'
sr = "40k"
num_proc = 54

#"Select the pitch extraction algorithm: when extracting singing, 
# you can use 'pm' to speed up. For high-quality speech with fast 
# performance, but worse CPU usage, you can use 'dio'. 'harvest' 
# results in better quality but is slower.  'rmvpe' has the best 
# results and consumes less CPU/GPU",
choices_f0method8=["pm", "harvest", "dio", "rmvpe", "rmvpe_gpu"]
f0method = "pm"

# # "Enter the GPU index(es) separated by '-', e.g., 
# # 0-1-2 to use GPU 0, 1, and 2:"
gpus6 = '' 

# "Whether the model has pitch guidance 
# (required for singing, optional for speech):"
if_f0 = True

# "Version"
# choices_version =["v1", "v2"]
version = "v2"

# "Enter the GPU index(es) separated by '-', e.g., 
# 0-0-1 to use 2 processes in GPU0 and 1 process in GPU1",
gpus_rmvpe = '0-0' # for no gpus

# speaker id???
spk_id = 0

# Save frequency (5)
save_epoch = 25

#Total training epochs (20)
total_epoch = 100

# Batch size per GPU (1)
batch_size = 20

# Save only the latest '.ckpt' file to save disk space: (No)
if_save_latest = 'No'

# Cache all training sets to GPU memory. Caching small datasets 
# (less than 10 minutes) can speed up training, but caching large datasets 
# will consume a lot of GPU memory and may not provide much speed improvement: (No)
if_cache_gpu = 'No'

# Save a small final model to the 'weights' folder at each save point: (No)
if_save_every_weights = 'No'

# Load pre-trained base model G path: (assets/pretrained_v2/f0G40k.pth)
pretrained_G = 'assets/pretrained_v2/f0G40k.pth'

# Load pre-trained base model D path: (assets/pretrained_v2/f0D40k.pth)
pretrained_D = 'assets/pretrained_v2/f0D40k.pth'

# Enter the GPU index(es) separated by '-', e.g., 0-1-2 to use GPU 0, 1, 
# and 2: (None but -??)
gpus = '0'