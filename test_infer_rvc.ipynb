{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dc4e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e002e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d67f5519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from infer_script.vc_script.modules import VC\n",
    "#from rvc.modules.vc.modules import VC\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "467abd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_input = '/Users/tomasandrade/Documents/BSC/ICHOIR/Retrieval-based-Voice-Conversion-WebUI'\n",
    "\n",
    "root_model = '/Users/tomasandrade/Documents/BSC/ICHOIR/Retrieval-based-Voice-Conversion/assets'\n",
    "root_output = '/Users/tomasandrade/Documents/BSC/ICHOIR/Retrieval-based-Voice-Conversion/output'\n",
    "\n",
    "model_name = 'maria-200_rmvpe_gpu'\n",
    "\n",
    "# model_pth = f'{root_web}/assets/weights/maria-20.pth'\n",
    "# index_file = f'{root_web}/logs/maria-20/added_IVF3808_Flat_nprobe_1_maria-20_v2.index'\n",
    "\n",
    "model_pth = f'{root_model}/{model_name}/{model_name}.pth'\n",
    "index_file = f'{root_model}/{model_name}/added_IVF3808_Flat_nprobe_1_maria-200-rmvpe_gpu_v2.index'\n",
    "\n",
    "hubert_path = f'{root_model}/hubert/hubert_base.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d056c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 03:01:32 | INFO | infer_script.configs_script.config | No supported Nvidia GPU found\n",
      "2025-01-06 03:01:32 | INFO | infer_script.configs_script.config | overwrite configs.json\n",
      "2025-01-06 03:01:32 | INFO | infer_script.configs_script.config | Use mps instead\n",
      "2025-01-06 03:01:32 | INFO | infer_script.configs_script.config | is_half:False, device:mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "vc = VC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6607703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 03:01:34 | INFO | infer_script.vc_script.modules | Get sid: maria-200_rmvpe_gpu.pth\n",
      "2025-01-06 03:01:34 | INFO | infer_script.vc_script.modules | Loading: /Users/tomasandrade/Documents/BSC/ICHOIR/Retrieval-based-Voice-Conversion/assets/maria-200_rmvpe_gpu/maria-200_rmvpe_gpu.pth\n",
      "2025-01-06 03:01:34 | INFO | infer_script.vc_script.modules | Select index: /Users/tomasandrade/Documents/BSC/ICHOIR/Retrieval-based-Voice-Conversion/assets/maria-200_rmvpe_gpu/added_IVF3808_Flat_nprobe_1_maria-200-rmvpe_gpu_v2.index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(109,\n",
       " [0.5, 0.33],\n",
       " '/Users/tomasandrade/Documents/BSC/ICHOIR/Retrieval-based-Voice-Conversion/assets/maria-200_rmvpe_gpu/added_IVF3808_Flat_nprobe_1_maria-200-rmvpe_gpu_v2.index')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.get_vc(model_pth, index_file = index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c3b9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_input = '/Users/tomasandrade/Documents/BSC/ICHOIR/Retrieval-based-Voice-Conversion/output'\n",
    "input_audio =  f'{root_input}/ame_campana_1.wav'\n",
    "#input_audio =  f'{root_input}/3_547.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f83c7455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasandrade/miniconda3/envs/rvc/lib/python3.9/site-packages/fairseq/utils.py:744: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:335.)\n",
      "  tensor[indices] = value\n",
      "/Users/tomasandrade/miniconda3/envs/rvc/lib/python3.9/site-packages/torch/nn/functional.py:4552: UserWarning: MPS: The constant padding of more than 3 dimensions is not currently supported natively. It uses View Ops default implementation to run. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Pad.mm:472.)\n",
      "  return torch._C._nn.pad(input, pad, mode, value)\n"
     ]
    }
   ],
   "source": [
    "tgt_sr, audio_opt, times, _ = vc.vc_inference(1, Path(input_audio), \n",
    "                                                hubert_path = hubert_path,\n",
    "                                                f0_method = \"pm\",\n",
    "                                                f0_up_key = 0,\n",
    "                                                protect = 0.33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b249c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path = f'{root_output}/campana_by_{model_name}.wav'\n",
    "output_path = f'{root_output}/ame_campana_1_by_{model_name}.wav'\n",
    "wavfile.write(output_path, tgt_sr, audio_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff507ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a5600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01 , 0.042, 0.074, 0.106, 0.138, 0.17 , 0.202, 0.234, 0.266,\n",
       "       0.298, 0.33 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protect_arr = np.linspace(0.01, 0.33, num=11)\n",
    "protect_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04276662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Working on protect = 0.01\n",
      "-------------- Working on protect = 0.042\n",
      "-------------- Working on protect = 0.074\n",
      "-------------- Working on protect = 0.106\n",
      "-------------- Working on protect = 0.138\n",
      "-------------- Working on protect = 0.17\n",
      "-------------- Working on protect = 0.202\n",
      "-------------- Working on protect = 0.234\n",
      "-------------- Working on protect = 0.266\n",
      "-------------- Working on protect = 0.29800000000000004\n",
      "-------------- Working on protect = 0.33\n"
     ]
    }
   ],
   "source": [
    "for protect in protect_arr:\n",
    "    print(f'-------------- Working on protect = {protect}')\n",
    "    tgt_sr, audio_opt, times, _ = vc.vc_inference(1, Path(input_audio), \n",
    "                                                hubert_path = hubert_path,\n",
    "                                                f0_method = \"pm\",\n",
    "                                                f0_up_key = 0,\n",
    "                                                protect=protect) \n",
    "\n",
    "    output_path = f'{root_output}/output/campana_protect_{protect:.3f}.wav'\n",
    "    wavfile.write(output_path, tgt_sr, audio_opt)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "rvc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
